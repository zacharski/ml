<!doctype html>
<!--[if lt IE 7 ]><html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]><html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]><html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]><html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!-->
<html lang="en" class="no-js"> <!--<![endif]-->
<head>
	<script type="text/javascript">var _sf_startpt = (new Date()).getTime()</script>
	<meta charset="utf-8">
	<!--[if IE]><meta content='IE=8' http-equiv='X-UA-Compatible' /><![endif]-->

	<title>Machine Learning Fundamentals | Working With Data</title>
  <meta name="description" content="Machine Learning Fundamentals">
  <meta name="author" content="">

  <meta property="og:title" content="Machine Learning Fundamentals" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="" />

	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<link rel="shortcut icon" href="/machine-learning/img/favicon.ico">
	<link rel="apple-touch-icon" href="/machine-learning/img/apple-touch-icon.png">

	<link rel="stylesheet" href="/machine-learning/css/p2pustrap-custom.css" />
	<link rel="stylesheet" href="/machine-learning/css/site.css" />
  

	<link rel="shortcut icon" href="/machine-learning/img/favicon.ico">
	<script type="text/javascript" src="/machine-learning/js/modernizr-2.6.2.min.js"></script>
</head>
<body 
      class="">

<!-- Navigation -->
<nav class="navbar navbar-default" role="navigation">

	<!-- Brand and toggle get grouped for better mobile display -->
	<div class="navbar-header">
		<a href="#" class="navbar-toggle" data-toggle="collapse" data-target="#p2pu-menu">
			<i class="fa fa-bars"></i>
		</a>
	</div>

	<!-- Collect the nav links, forms, and other content for toggling -->
	<div class="container">
		<div class="collapse navbar-collapse" id="p2pu-menu">
			<ul class="nav navbar-nav">
				<li>
					<a href="/machine-learning/"><i class="fa fa-home"></i></a>
				</li>
				
					
					<li class="dropdown active first ">
						<a href="/machine-learning/modules/basics/Intro-To-Basic-ML/"
						   class="dropdown-item">
							basics
						</a>
					</li>
				
					
					<li class="dropdown   ">
						<a href="/machine-learning/modules/boosting/Intro-to-Boosting/"
						   class="dropdown-item">
							boosting
						</a>
					</li>
				
					
					<li class="dropdown   last">
						<a href="/machine-learning/modules/deep%20learning/Deep-Learning-Intro/"
						   class="dropdown-item">
							deep learning
						</a>
					</li>
				
				
		</div>
		<!-- /.navbar-collapse -->
	</div>
	<!-- /.container-fluid -->
</nav>
<!-- End Navigation -->



<div class="clearfix">
	<div class="sidebar col-md-3">
	







	
	<ul>
		
			<li class=" first ">
				<a
						href="/machine-learning/modules/basics/Intro-To-Basic-ML/">
					Intro To Basic Ml
				</a>
			</li>
		
			<li class="  ">
				<a
						href="/machine-learning/modules/basics/kNN/">
					Knn
				</a>
			</li>
		
			<li class="  ">
				<a
						href="/machine-learning/modules/basics/Colab-and-Numpy/">
					Colab And Numpy
				</a>
			</li>
		
			<li class="  ">
				<a
						href="/machine-learning/modules/basics/Pandas/">
					Pandas
				</a>
			</li>
		
			<li class="  ">
				<a
						href="/machine-learning/modules/basics/SciKit-Learn/">
					 scikit Learn
				</a>
			</li>
		
			<li class="  ">
				<a
						href="/machine-learning/modules/basics/Decision-Trees/">
					 decision Trees
				</a>
			</li>
		
			<li class="active  last">
				<a
						href="/machine-learning/modules/basics/WOrking-With-Data/">
					Working With Data
				</a>
			</li>
		
	</ul>
	
		<hr />
		<div class="pagination-section">
			<div class="title">
				Next module:
			</div>
			<a rel="next" class="next" href="/machine-learning/modules/boosting/Intro-to-Boosting/"> boosting
			</a>
		</div>
	
</div>
	<div class="col-md-9 background-white">
		<div class="col-md-8 col-md-offset-1">
			<div class="row">
				<div class="content col-lg-12">
					<h2 id="working-with-data">Working With Data</h2>

<iframe width="560" height="315" src="https://www.youtube.com/embed/mlAZpVEYIio" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h3 id="one-hot-encoding">One Hot Encoding</h3>

<p><img src="https://raw.githubusercontent.com/zacharski/ml-class/master/jumpstart/pics/biking.webp" alt="" /></p>

<p>start with our mountain bike example we worked through</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd
bike = pd.read_csv('https://raw.githubusercontent.com/zacharski/ml-class/master/data/bike.csv')
bike = bike.set_index('Day')
bike
</code></pre></div></div>

<h4 id="now-divide-into-features-and-labels">now divide into features and labels</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>features = ['Outlook', 'Temperature', 'Humidity', 'Wind']
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bikeFeatures = bike[features]
bikeLabels = bike['Bike']
bikeFeatures
</code></pre></div></div>

<h4 id="now-try-to-train-a-classifier">Now try to train a classifier</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn import tree
clf = tree.DecisionTreeClassifier(criterion='entropy')
clf.fit(bikeFeatures, bikeLabels)
</code></pre></div></div>

<p>And we get the error:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------

    ValueError                                Traceback (most recent call last)

    &lt;ipython-input-41-7c3bf8ef85f2&gt; in &lt;module&gt;()
          1 from sklearn import tree
          2 clf = tree.DecisionTreeClassifier(criterion='entropy')
    ----&gt; 3 clf.fit(bikeFeatures, bikeLabels)


    /usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py in fit(self, X, y, sample_weight, check_input, X_idx_sorted)
        875             sample_weight=sample_weight,
        876             check_input=check_input,
    --&gt; 877             X_idx_sorted=X_idx_sorted)
        878         return self
        879


    /usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py in fit(self, X, y, sample_weight, check_input, X_idx_sorted)
        147
        148         if check_input:
    --&gt; 149             X = check_array(X, dtype=DTYPE, accept_sparse="csc")
        150             y = check_array(y, ensure_2d=False, dtype=None)
        151             if issparse(X):


    /usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)
        529                     array = array.astype(dtype, casting="unsafe", copy=False)
        530                 else:
    --&gt; 531                     array = np.asarray(array, order=order, dtype=dtype)
        532             except ComplexWarning:
        533                 raise ValueError("Complex data not supported\n"


    /usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py in asarray(a, dtype, order)
         83
         84     """
    ---&gt; 85     return array(a, dtype, copy=False, order=order)
         86
         87


    ValueError: could not convert string to float: 'Sunny'
    ```
</code></pre></div></div>

<p>We get the error because the string “Sunny” is obviously not a number. We need to one hot encode this DataFrame.</p>

<h4 id="one-hot-encoding-1">One Hot Encoding</h4>

<p>I am going to show you one way that also gives you a good visualization. Then I will show you a slightly better way.</p>

<ol>
  <li>Create a new Dataframe of the one-hot encoded values for the Outlook column.</li>
  <li>Drop the Outlook column from the original Dataframe.</li>
  <li>Join the new one-hot encoded Dataframe to the original.</li>
</ol>

<h4 id="1-create-the-new-dataframe">1. Create the new DataFrame</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bikeFeatures1 = bikeFeatures

one_hot = pd.get_dummies(bikeFeatures1['Outlook'])
one_hot
</code></pre></div></div>

<h4 id="2-drop-the-original-outlook-column">2. drop the original outlook column</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bikeFeatures1 = bikeFeatures1.drop('Outlook', axis=1)
bikeFeatures1
</code></pre></div></div>

<h4 id="3-join-the-one-hot-encoded-columns-to-the-original-df">3. Join the one hot encoded columns to the original DF</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bikeFeatures1 = bikeFeatures1.join(one_hot)
bikeFeatures1
</code></pre></div></div>

<p>We could just repeat this for all the columns. But we can make it a bit more automatic.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def onehot(originalDF, categories):
  final = originalDF
  for category in categories:
    final = final.join(pd.get_dummies(final[category], prefix=category))
    final = final.drop(category, axis=1)
  return final
</code></pre></div></div>

<h4 id="use-the-function-to-one-hot-encode-the-dataframe">use the function to one hot encode the DataFrame</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bikeFeatures2 = onehot(bikeFeatures, ['Outlook', 'Temperature', 'Humidity', 'Wind'])
bikeFeatures2
</code></pre></div></div>

<p>You can compare that to our original DataFrame:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bikeFeatures
</code></pre></div></div>

<p>So, in the one hot encoded version there is a ‘1’ when that instance has that features and a ‘0’ when it does not.</p>

<h4 id="sklearns-onehotencoder">sklearn’s onehotencoder</h4>

<h5 id="compressed-sparse-row-format">Compressed Sparse Row format</h5>

<h5 id="aka-yale-format">AKA Yale Format</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.preprocessing import OneHotEncoder
enc = OneHotEncoder(handle_unknown='ignore')
bikeSparse = enc.fit_transform(bikeFeatures)
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import scipy
bikeSparse
scipy.sparse.find(bikeSparse)
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([ 2,  6, 11, 12,  3,  4,  5,  9, 13,  0,  1,  7,  8, 10,  4,  5,  6,
         8,  0,  1,  2, 12,  3,  7,  9, 10, 11, 13,  0,  1,  2,  3,  7, 11,
        13,  4,  5,  6,  8,  9, 10, 12,  1,  5,  6, 10, 11, 13,  0,  2,  3,
         4,  7,  8,  9, 12], dtype=int32),
 array([0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4,
        5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8,
        8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int32),
 array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1.]))
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bikeFeatures2
</code></pre></div></div>

<p>So the Compressed Sparse Row format consists of three arrays. The first array represents the row number that contains a non-zero number. The second contains the column number, and the third contains the non-zero value.</p>

<ul>
  <li>The first element of the second array is 0</li>
  <li>The first element of the first array is 2</li>
  <li>The first element of the third array is 1</li>
</ul>

<p>This means that there is a 1 (3rd array) in column 0 (2nd array) row 2 (1st array)</p>

<p>The next entries in the arrays say that there is a 1 in column 0 row 6.</p>

<p>Even though this looks substantially different than a standard DataFrame we can still use it in sklearn:</p>

<h5 id="fit-the-decision-tree">Fit the decision tree</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clf.fit(bikeSparse, bikeLabels)
</code></pre></div></div>

<h2 id="view-decision-tree">View decision tree</h2>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image
import pydotplus
dot_data = tree.export_graphviz(clf, out_file="biker.dot",
                         feature_names=enc.get_feature_names(),
                         class_names=['did not', 'biked'],
                         filled=True, rounded=True,
                         special_characters=True)
graph = pydotplus.graphviz.graph_from_dot_file("biker.dot")
#graph = pydotplus.graph_from_dot_data(dot_data)
Image(graph.create_png())
</code></pre></div></div>

<p><img src="/machine-learning/img/DemoWorkingWithData_26_0.png" alt="png" /></p>

<p>This looks fantastic!</p>

<h3 id="cross-validation-and-hyperparameters">cross validation and hyperparameters</h3>

<p><img src="https://raw.githubusercontent.com/zacharski/ml-class/master/jumpstart/pics/radar.png" alt="" /></p>

<p><img src="https://raw.githubusercontent.com/zacharski/ml-class/master/jumpstart/pics/radar2.png" alt="" /></p>

<p>We have 16 antenna and 2 values from each. and the label we want to predict is whether the measurement is good or bad. (Is it suitable for further analysis)</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd
radar = pd.read_csv('https://raw.githubusercontent.com/zacharski/ml-class/master/data/ionosphere.csv', header=None)
radar
</code></pre></div></div>

<p>We do our standard division of training and testing and features and labels.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.model_selection import train_test_split
radar_train, radar_test = train_test_split(radar, test_size = 0.2)
radar_train
radar_train_features = radar_train.drop(34, axis=1)
radar_train_labels = radar_train[34]
radar_test_features = radar_test.drop(34, axis=1)
radar_test_labels = radar_test[34]

radar_train_labels

</code></pre></div></div>

<h2 id="now-create-a-classifier">now create a classifier</h2>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn import tree
clf = tree.DecisionTreeClassifier(criterion='entropy')
</code></pre></div></div>

<h4 id="cross-validation-steps">Cross Validation Steps</h4>

<h5 id="1-import-cross_val_score">1. import cross_val_score</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.model_selection import cross_val_score
</code></pre></div></div>

<h5 id="2-run-cross-validation">2. run cross validation</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scores = cross_val_score(clf, radar_train_features, radar_train_labels, cv=10)
</code></pre></div></div>

<p><code class="highlighter-rouge">cv=10</code> specified that we perform 10-fold cross validation. the function returns a 10 element array, where each element is the accuracy of that fold. Let’s take a look:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(scores)
print("The average accuracy is %5.3f" % (scores.mean()))
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.92857143 0.89285714 0.92857143 0.92857143 0.92857143 0.89285714
 0.82142857 0.89285714 0.96428571 0.89285714]
The average accuracy is 0.907
</code></pre></div></div>

<p>So <code class="highlighter-rouge">scores</code> contains the accuracy for each of the 10 runs.</p>

<h5 id="try-with-max-depth-of-5">Try with max depth of 5</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn import tree
clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scores = cross_val_score(clf, radar_train_features, radar_train_labels, cv=10)
print(scores)
print("The average accuracy is %5.3f" % (scores.mean()))
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.89285714 0.82142857 1.         0.82142857 0.92857143 0.89285714
 0.78571429 0.92857143 0.92857143 0.89285714]
The average accuracy is 0.889
</code></pre></div></div>

<h4 id="once-we-find-the-best-hyperparameters">Once we find the best hyperparameters.</h4>

<h5 id="train-a-classifier-on-the-entire-training-set">Train a classifier on the entire training set.</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clfF = tree.DecisionTreeClassifier(criterion='entropy')
clfF.fit(radar_train_features, radar_train_labels)

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=None, splitter='best')
</code></pre></div></div>

<h5 id="now-test-and-report-accuracy">Now test and report accuracy</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>predictions = clfF.predict(radar_test_features)
from sklearn.metrics import accuracy_score
accuracy_score(radar_test_labels, predictions)
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.8873239436619719
</code></pre></div></div>

<h5 id="it-is-a-hassle-to-do-this-manually">It is a hassle to do this manually</h5>

<p>Let’s say we want to find the best settings for max_depthand we will check out the values, 3, 4, 5, 6, …12 and the best for min_samples_split and we will try 2, 3, 4, 5. That makes 10 values for max_depth and 4 for min_samples_split. That makes 40 different classifiers and it would be time consuming to do that by hand. Fortunately, we can automate the process using GridSearchCV.</p>

<p>First we will import the module:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.model_selection import GridSearchCV
</code></pre></div></div>

<p>Now we are going to specify the values we want to test. For <code class="highlighter-rouge">max_depth</code> we want 3, 4, 5, 6, … 12 and for <code class="highlighter-rouge">min_samples_split</code> we want 2, 3, 4, 5:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hyperparam_grid = [
    {'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12],
     'min_samples_split': [2,3,4, 5]}
  ]
</code></pre></div></div>

<h5 id="create-a-decision-tree-classifier">Create a decision tree classifier</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clf = tree.DecisionTreeClassifier(criterion='entropy')
</code></pre></div></div>

<p>and perform the grid search</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>grid_search = GridSearchCV(clf, hyperparam_grid, cv=10)
</code></pre></div></div>

<p><strong>note</strong>
When we create the object we pass in:</p>

<ul>
  <li>the classifer - in our case <code class="highlighter-rouge">clf</code></li>
  <li>the Python dictionary containing the hyperparameters we want to evaluate. In our case <code class="highlighter-rouge">hyperparam_grid</code></li>
  <li>how many bins we are using. In our case 10: <code class="highlighter-rouge">cv=10</code></li>
</ul>

<h5 id="now-perform-fit">now perform <code class="highlighter-rouge">fit</code></h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>grid_search.fit(radar_train_features, radar_train_labels)
</code></pre></div></div>

<p>which outputs …</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
    GridSearchCV(cv=10, error_score=nan,
                 estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                                  criterion='entropy',
                                                  max_depth=None, max_features=None,
                                                  max_leaf_nodes=None,
                                                  min_impurity_decrease=0.0,
                                                  min_impurity_split=None,
                                                  min_samples_leaf=1,
                                                  min_samples_split=2,
                                                  min_weight_fraction_leaf=0.0,
                                                  presort='deprecated',
                                                  random_state=None,
                                                  splitter='best'),
                 iid='deprecated', n_jobs=None,
                 param_grid=[{'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12],
                              'min_samples_split': [2, 3, 4, 5]}],
                 pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
                 scoring=None, verbose=0)

</code></pre></div></div>

<p>When <code class="highlighter-rouge">grid_search</code> runs, it creates 40 different classifiers and runs 10-fold cross validation on each of them. We can ask <code class="highlighter-rouge">grid_search</code> what were the parameters of the classifier with the highest accuracy:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
grid*search.best_params*

</code></pre></div></div>

<p>this displays …</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
    {'max_depth': 9, 'min_samples_split': 2}
</code></pre></div></div>

<p>we can return the best classifier</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
predictions = grid*search.best_estimator*.predict(radar_test_features)

</code></pre></div></div>

<p>and now get the accuracy</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
accuracy_score(radar_test_labels, predictions)



    0.8873239436619719

</code></pre></div></div>

					





					
						<hr />
					
					
						<div class="pagination-section pull-left">
							<div class="title">
								Previous section:
							</div>
							<a rel="prev" class="prev" href="/machine-learning/modules/basics/Decision-Trees/">
								 decision Trees </a>
						</div>
					
					
				</div>
			</div>
		</div>
	</div>
</div>


<footer class="p2pu-footer">
  <div class="container">
    <div class="row">
      <div class="col-sm-3 col-sm-offset-3">
        <a href="https://inquiryum.com/" class="image-link"
          ><img
            id="cmp-logo"
            src="/machine-learning/img/inquiryum-logo.png"
            class="img-responsive"
        /></a>
      </div>

      <div class="col-sm-3">
        <a href="https://www.imls.gov" class="image-link"
          ><img src="/machine-learning/img/footer2.png" class="img-responsive"
        /></a>
      </div>
    </div>

    <div class="row">
      <div class="col-sm-6 col-sm-offset-3" id="p2pu-content">
        <p>
          Built using <a href="http://howto.p2pu.org">Course in a Box</a>, a
          project of
        </p>
        <a href="https://www.p2pu.org" class="image-link"
          ><img
            src="/machine-learning/img/p2pu-logo-2x-white.png"
            alt="P2PU logo"
        /></a>
      </div>
    </div>

    <div class="row">
      <div class="col-sm-10 col-sm-offset-1 cc-by-sa">
        <img
          src="/machine-learning/img/cc-icons.png"
          alt="CC-BY-SA Icon"
          class="img-responsive"
        />
        <p>
          Unless otherwise noted, all the materials on this site are licensed
          under a
          <a
            target="_blank"
            href="http://creativecommons.org/licenses/by-sa/4.0/"
          >
            Creative Commons Attribution Share Alike 4.0</a
          >
          Unported license.
        </p>
      </div>
    </div>
  </div>
</footer>


<script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script>
  window.jQuery || document.write('<script src="/machine-learning/js/jquery.min.js"><\/script>')
</script>

<script src="//netdna.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>
<script type="text/javascript"
        src="//s3.amazonaws.com/p2pu-navigation-widget/p2pu_menu_slider.js"></script>
<script src="/machine-learning/js/init.js"></script>
<script src="/machine-learning/js/gh_link_helper.js"></script>



<script>
	P2PU.ciab.init();
</script>



<!-- Google Analytics -->

	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  
    ga('create', 'UA-5757664-19', 'auto');
  
  
    ga('create', 'UA-55722824-1', 'auto', {'name': 'p2puTracker'} );
  
  
    ga('send', 'pageview');
  
  
    ga('p2puTracker.send', 'pageview');
  
</script>



</body>
</html>
